{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used for cleaning the data and creating two datasets that will later be used in fake and real news article classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_original = pd.read_csv(\"Raw_datasets/Fake.csv\")\n",
    "true_original = pd.read_csv(\"Raw_datasets/True.csv\")\n",
    "mixture = pd.read_csv(\"Raw_datasets/news_articles.csv\")\n",
    "fake = fake_original.copy()\n",
    "true = true_original.copy()\n",
    "mixture_clean = mixture.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_clean = mixture_clean.dropna()\n",
    "mixture_clean = mixture_clean[['title','text', 'published', 'label', 'title_without_stopwords','text_without_stopwords']]\n",
    "\n",
    "fake = fake.dropna()\n",
    "true = true.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCorrect(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('u.s', 'xUSx', text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\", \" \", text)\n",
    "    text = re.sub(\"https?://\\S+|www\\. \\S+\", \"\", text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('xUSx', 'u.s', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_clean.rename(columns={\"published\":\"date\"}, inplace=True)\n",
    "#YYYY-MM-DDThh:mm:ss.sTZD our current date format.\n",
    "\n",
    "mixture_clean = mixture_clean[~mixture_clean.date.str.contains('http')]\n",
    "\n",
    "\n",
    "\n",
    "mixture_clean['date'] = pd.to_datetime(mixture_clean['date'], utc=True)\n",
    "mixture_clean.date = pd.to_datetime(mixture_clean.date).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = fake[fake.date.str.contains('20')]\n",
    "true = true[true.date.str.contains('20')]\n",
    "\n",
    "#in case some URL has 20 written inside of them.\n",
    "fake = fake[~fake.date.str.contains('http')]\n",
    "true = true[~true.date.str.contains('http')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake['date'] = pd.to_datetime(fake['date'])\n",
    "true['date'] = pd.to_datetime(true['date'])\n",
    "fake.drop(['subject'], axis=1, inplace=True)\n",
    "true.drop(['subject'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_clean['title'] = mixture_clean['title'].apply(wordCorrect)\n",
    "mixture_clean['text'] = mixture_clean['text'].apply(wordCorrect)\n",
    "mixture_clean['title_without_stopwords'] = mixture_clean['title_without_stopwords'].apply(wordCorrect)\n",
    "mixture_clean['text_without_stopwords'] = mixture_clean['text_without_stopwords'].apply(wordCorrect)\n",
    "\n",
    "fake['title'] = fake['title'].apply(wordCorrect)\n",
    "true['title'] = true['title'].apply(wordCorrect)\n",
    "\n",
    "true['text'] = true['text'].apply(wordCorrect)\n",
    "fake['text'] = fake['text'].apply(wordCorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_real = mixture_clean['label'] == 'Real'\n",
    "mix_true_stop = mixture_clean[is_real]\n",
    "mix_true_stop = mix_true_stop.drop(['title', 'label', 'text'], axis=1)\n",
    "\n",
    "mix_true = mixture_clean[is_real]\n",
    "mix_true = mix_true.drop(['title_without_stopwords', 'text_without_stopwords', 'label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_fake_stop = mixture_clean[~is_real]\n",
    "mix_fake_stop = mix_fake_stop.drop(['title', 'label', 'text'], axis=1)\n",
    "\n",
    "mix_fake = mixture_clean[~is_real]\n",
    "mix_fake = mix_fake.drop(['title_without_stopwords', 'text_without_stopwords', 'label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct order of columns should be [title, text, date]\n",
    "mix_true_stop = mix_true_stop[['title_without_stopwords', 'text_without_stopwords', 'date']]\n",
    "mix_fake_stop = mix_fake_stop[['title_without_stopwords', 'text_without_stopwords', 'date']]\n",
    "\n",
    "mix_true = mix_true[['title','text','date']]\n",
    "mix_fake = mix_fake[['title','text','date']]\n",
    "\n",
    "mix_fake_stop.reset_index(drop=True, inplace=True)\n",
    "mix_true_stop.reset_index(drop=True, inplace=True)\n",
    "mix_true.reset_index(drop=True, inplace=True)\n",
    "mix_fake.reset_index(drop=True, inplace=True)\n",
    "fake.reset_index(drop=True, inplace=True)\n",
    "true.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_true.to_csv('Datasets/mix_true.csv', header =True)\n",
    "mix_fake.to_csv('Datasets/mix_fake.csv', header =True)\n",
    "\n",
    "fake.to_csv('Datasets/fake.csv', header =True)\n",
    "true.to_csv('Datasets/true.csv', header =True)\n",
    "\n",
    "mix_true_stop.to_csv('Datasets/mix_true_with_stop.csv', header =True)\n",
    "mix_fake_stop.to_csv('Datasets/mix_fake_with_stop.csv', header =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake['legit'] = 0\n",
    "true['legit'] = 1\n",
    "mix_true['legit'] = 1\n",
    "mix_fake['legit'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeTrue = pd.concat([fake,true])\n",
    "fakeTrue.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mix_trueFake = pd.concat([mix_true, mix_fake])\n",
    "mix_trueFake.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeTrue.to_csv('Datasets/fakeTrue.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_trueFake.to_csv('Datasets/testData.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
